# ç¬¬ä¸‰æ–¹å°ˆå®¶å•é¡Œå›è¦†

## å•é¡Œ 1: è³‡æ–™ä¾†æºå†—é¤˜èˆ‡ä¸€è‡´æ€§

### å•é¡Œæ ¸å¿ƒ
ç•¶æ’è¡Œæ¦œ API æˆ–æ–°èä¾†æºåŒæ™‚å‡ºç¾å»¶é²æˆ–æ•¸æ“šä¸ä¸€è‡´æ™‚ï¼Œç³»çµ±å¦‚ä½•ç¢ºä¿ã€ŒTopic Collectorã€æ¨¡çµ„ä»èƒ½ç”¢å‡ºç©©å®šä¸”å¯ä¿¡çš„ä¸»é¡Œï¼Ÿ

### ç¾æœ‰è¨­è¨ˆ
ç›®å‰ç³»çµ±å·²æœ‰åŸºæœ¬çš„ Fallback æ©Ÿåˆ¶ï¼Œä½†ç¼ºä¹è·¨ä¾†æºæ¯”å°èˆ‡ä¸€è‡´æ€§æª¢æŸ¥ã€‚

### å»ºè­°è§£æ±ºæ–¹æ¡ˆ

#### 1.1 å¤šå±¤å‚™æ´æ©Ÿåˆ¶ï¼ˆ3-2-1 ç­–ç•¥ï¼‰

```
ç¬¬ä¸€å±¤ï¼šä¸»è¦ä¾†æºï¼ˆ3å€‹ï¼‰
  â”œâ”€â”€ Vogue Trending (æ™‚å°š)
  â”œâ”€â”€ Google Trends (ç¾é£Ÿ)
  â””â”€â”€ å­¸è¡“è³‡æ–™åº« (ç¤¾æœƒè¶¨å‹¢)

ç¬¬äºŒå±¤ï¼šå‚™ç”¨ä¾†æºï¼ˆ2å€‹ï¼‰
  â”œâ”€â”€ WWD / å¾®åšç†±æœ
  â””â”€â”€ OpenRice / å¤§çœ¾é»è©•

ç¬¬ä¸‰å±¤ï¼šFallbackï¼ˆ1å€‹ï¼‰
  â””â”€â”€ é è¨­é—œéµå­—åº«ï¼ˆAIç”Ÿæˆï¼‰
```

**å¯¦ç¾é‚è¼¯**:
```python
async def collect_topics_with_fallback(category, count=3):
    # å˜—è©¦ä¸»è¦ä¾†æº
    topics = await try_primary_sources(category, count)
    if len(topics) >= count:
        return topics
    
    # å˜—è©¦å‚™ç”¨ä¾†æº
    topics.extend(await try_backup_sources(category, count - len(topics)))
    if len(topics) >= count:
        return topics
    
    # ä½¿ç”¨ Fallback
    topics.extend(await use_fallback_keywords(category, count - len(topics)))
    return topics
```

#### 1.2 è·¨ä¾†æºä¸€è‡´æ€§æª¢æŸ¥æ©Ÿåˆ¶

**è¨­è¨ˆåŸå‰‡**: è‡³å°‘2å€‹ä¾†æºé©—è­‰åŒä¸€é—œéµå­—ï¼Œæ‰è¦–ç‚ºå¯ä¿¡

**å¯¦ç¾é‚è¼¯**:
```python
async def validate_topic_consistency(keyword, category):
    """
    è·¨ä¾†æºä¸€è‡´æ€§æª¢æŸ¥
    """
    sources = await fetch_from_multiple_sources(keyword, category)
    
    # æª¢æŸ¥ä¾†æºæ•¸é‡
    if len(sources) < 2:
        return {
            "valid": False,
            "reason": "ä¾†æºä¸è¶³ï¼Œéœ€è¦è‡³å°‘2å€‹ä¾†æºé©—è­‰"
        }
    
    # æª¢æŸ¥é—œéµå­—ä¸€è‡´æ€§
    keyword_similarity = calculate_keyword_similarity(sources)
    if keyword_similarity < 0.7:
        return {
            "valid": False,
            "reason": "é—œéµå­—ä¸ä¸€è‡´ï¼Œç›¸ä¼¼åº¦ä½æ–¼70%"
        }
    
    # æª¢æŸ¥æ™‚é–“ä¸€è‡´æ€§ï¼ˆé—œéµå­—æ‡‰åœ¨ç›¸è¿‘æ™‚é–“å‡ºç¾ï¼‰
    time_consistency = check_time_consistency(sources)
    if not time_consistency:
        return {
            "valid": False,
            "reason": "æ™‚é–“ä¸ä¸€è‡´ï¼Œå¯èƒ½ä¸æ˜¯ç†±é–€è©±é¡Œ"
        }
    
    return {
        "valid": True,
        "confidence": calculate_confidence(sources),
        "sources": sources
    }
```

#### 1.3 ä¾†æºå¥åº·åº¦ç›£æ§

**ç›£æ§æŒ‡æ¨™**:
- éŸ¿æ‡‰æ™‚é–“ï¼ˆ< 3ç§’ç‚ºå¥åº·ï¼‰
- æˆåŠŸç‡ï¼ˆ> 95%ç‚ºå¥åº·ï¼‰
- æ•¸æ“šæ–°é®®åº¦ï¼ˆ< 1å°æ™‚ç‚ºæ–°é®®ï¼‰

**è‡ªå‹•åˆ‡æ›æ©Ÿåˆ¶**:
```python
class SourceHealthMonitor:
    async def check_source_health(self, source_url):
        health_score = 0
        
        # æª¢æŸ¥éŸ¿æ‡‰æ™‚é–“
        response_time = await measure_response_time(source_url)
        if response_time < 3:
            health_score += 0.4
        elif response_time < 5:
            health_score += 0.2
        
        # æª¢æŸ¥æˆåŠŸç‡ï¼ˆéå»24å°æ™‚ï¼‰
        success_rate = await get_success_rate(source_url, hours=24)
        if success_rate > 0.95:
            health_score += 0.4
        elif success_rate > 0.90:
            health_score += 0.2
        
        # æª¢æŸ¥æ•¸æ“šæ–°é®®åº¦
        data_freshness = await get_data_freshness(source_url)
        if data_freshness < 3600:  # 1å°æ™‚å…§
            health_score += 0.2
        
        return {
            "source": source_url,
            "health_score": health_score,
            "status": "healthy" if health_score > 0.7 else "degraded" if health_score > 0.4 else "unhealthy"
        }
```

#### 1.4 ä¸€è‡´æ€§æª¢æŸ¥ API

**æ–°å¢ç«¯é»**: `POST /api/v1/validate/topic-consistency`

**åŠŸèƒ½**: é©—è­‰ä¸»é¡Œçš„è·¨ä¾†æºä¸€è‡´æ€§

**Request**:
```json
{
  "keyword": "Dior 2026 æ˜¥å¤ç§€",
  "category": "fashion",
  "sources": [
    {"name": "Vogue", "url": "https://vogue.com/..."},
    {"name": "WWD", "url": "https://wwd.com/..."}
  ]
}
```

**Response**:
```json
{
  "valid": true,
  "confidence": 0.85,
  "consistency_score": 0.92,
  "sources_verified": 2,
  "warnings": []
}
```

---

## å•é¡Œ 2: ç…§ç‰‡åŒ¹é…é©—è­‰æµç¨‹

### å•é¡Œæ ¸å¿ƒ
è‹¥æ–‡å­—æè¿°çš„ç´°ç¯€ï¼ˆå¦‚é¡è‰²ã€æè³ªï¼‰åœ¨ç…§ç‰‡ä¸­ç„¡æ³•å®Œå…¨é©—è­‰ï¼Œç³»çµ±æ˜¯å¦éœ€è¦å¼•å…¥ NLP + CV çš„äº¤å‰æª¢æŸ¥ï¼Ÿ

### ç¾æœ‰è¨­è¨ˆ
ç›®å‰åƒ…æœ‰åŸºæœ¬çš„é—œéµå­—åŒ¹é…ï¼Œç¼ºä¹è¦–è¦ºé©—è­‰ã€‚

### å»ºè­°è§£æ±ºæ–¹æ¡ˆ

#### 2.1 NLP + CV äº¤å‰æª¢æŸ¥æ©Ÿåˆ¶

**æµç¨‹è¨­è¨ˆ**:
```
æ–‡å­—æè¿° â†’ NLPæå–ç‰¹å¾µ â†’ ç”Ÿæˆè¦–è¦ºç‰¹å¾µæè¿°
    â†“
ç…§ç‰‡ â†’ CVåˆ†æ â†’ æå–è¦–è¦ºç‰¹å¾µ
    â†“
ç‰¹å¾µæ¯”å° â†’ åŒ¹é…åº¦è©•åˆ† â†’ æ±ºå®šæ˜¯å¦ä½¿ç”¨
```

**å¯¦ç¾é‚è¼¯**:
```python
async def validate_photo_match(article_text, photo_url):
    """
    NLP + CV äº¤å‰æª¢æŸ¥ç…§ç‰‡åŒ¹é…åº¦
    """
    # Step 1: NLP æå–æ–‡å­—ä¸­çš„è¦–è¦ºç‰¹å¾µ
    visual_features = await extract_visual_features_from_text(article_text)
    # ä¾‹å¦‚: {"color": "white", "material": "lace", "style": "dress"}
    
    # Step 2: CV åˆ†æç…§ç‰‡
    photo_features = await analyze_photo_with_cv(photo_url)
    # ä¾‹å¦‚: {"dominant_color": "white", "detected_objects": ["dress", "lace"]}
    
    # Step 3: ç‰¹å¾µæ¯”å°
    match_score = calculate_match_score(visual_features, photo_features)
    
    # Step 4: æ±ºå®šæ˜¯å¦ä½¿ç”¨
    if match_score >= 0.7:
        return {
            "valid": True,
            "match_score": match_score,
            "matched_features": get_matched_features(visual_features, photo_features)
        }
    else:
        return {
            "valid": False,
            "match_score": match_score,
            "missing_features": get_missing_features(visual_features, photo_features),
            "suggestion": "éœ€è¦é‡æ–°æœå°‹æ›´åŒ¹é…çš„ç…§ç‰‡"
        }
```

#### 2.2 è¦–è¦ºç‰¹å¾µæå–è¦å‰‡

**æ–‡å­—ç‰¹å¾µæå–**:
```python
def extract_visual_features_from_text(text):
    """
    å¾æ–‡å­—ä¸­æå–è¦–è¦ºç‰¹å¾µ
    """
    features = {
        "colors": extract_colors(text),  # ["white", "black"]
        "materials": extract_materials(text),  # ["lace", "silk"]
        "objects": extract_objects(text),  # ["dress", "bag"]
        "styles": extract_styles(text),  # ["elegant", "casual"]
        "details": extract_details(text)  # ["long sleeve", "high neck"]
    }
    return features
```

**ç…§ç‰‡ç‰¹å¾µåˆ†æ**:
```python
async def analyze_photo_with_cv(photo_url):
    """
    ä½¿ç”¨è¨ˆç®—æ©Ÿè¦–è¦ºåˆ†æç…§ç‰‡
    """
    # ä½¿ç”¨é è¨“ç·´æ¨¡å‹ï¼ˆå¦‚ CLIPã€ResNetï¼‰
    analysis = await cv_service.analyze(photo_url)
    
    return {
        "dominant_colors": analysis.colors,  # ä¸»è¦é¡è‰²
        "detected_objects": analysis.objects,  # æª¢æ¸¬åˆ°çš„ç‰©ä»¶
        "scene_type": analysis.scene,  # å ´æ™¯é¡å‹
        "style_tags": analysis.style_tags  # é¢¨æ ¼æ¨™ç±¤
    }
```

#### 2.3 äººå·¥ Fallback æ©Ÿåˆ¶

**è§¸ç™¼æ¢ä»¶**:
1. åŒ¹é…åº¦ < 0.7ï¼ˆè‡ªå‹•è§¸ç™¼ï¼‰
2. é—œéµç‰©ä»¶ç„¡æ³•åŒ¹é…ï¼ˆå¦‚ã€Œç‡’è³£çš‡åã€çš„åœ°å€ç…§ç‰‡ï¼‰
3. é¡§å®¢æ‰‹å‹•æ¨™è¨˜ä¸åŒ¹é…

**äººå·¥å¯©æ ¸æµç¨‹**:
```python
class PhotoMatchReviewQueue:
    async def add_to_review_queue(self, topic_id, photo_id, reason):
        """
        å°‡ä¸åŒ¹é…çš„ç…§ç‰‡åŠ å…¥äººå·¥å¯©æ ¸éšŠåˆ—
        """
        review_item = {
            "topic_id": topic_id,
            "photo_id": photo_id,
            "reason": reason,
            "status": "pending",
            "created_at": datetime.utcnow(),
            "priority": "high" if reason == "critical_mismatch" else "normal"
        }
        await self.review_queue.insert_one(review_item)
    
    async def get_pending_reviews(self, limit=10):
        """
        å–å¾—å¾…å¯©æ ¸é …ç›®
        """
        return await self.review_queue.find({
            "status": "pending"
        }).sort("priority", -1).limit(limit).to_list()
```

#### 2.4 ç…§ç‰‡åŒ¹é…é©—è­‰ API

**æ–°å¢ç«¯é»**: `POST /api/v1/photos/validate-match`

**åŠŸèƒ½**: é©—è­‰ç…§ç‰‡èˆ‡æ–‡å­—çš„åŒ¹é…åº¦

**Request**:
```json
{
  "topic_id": "topic_fashion_20251230090000_0",
  "article_id": "content_topic_fashion_20251230090000_0",
  "photo_id": "img_001"
}
```

**Response**:
```json
{
  "valid": true,
  "match_score": 0.85,
  "matched_features": {
    "color": "white",
    "material": "lace",
    "object": "dress"
  },
  "missing_features": [],
  "cv_analysis": {
    "dominant_color": "white",
    "detected_objects": ["dress", "lace"],
    "confidence": 0.92
  }
}
```

---

## å•é¡Œ 3: åå¥½æ¨¡å‹å†·å•Ÿå‹•ç­–ç•¥

### å•é¡Œæ ¸å¿ƒ
å†·å•Ÿå‹•æ™‚ä½¿ç”¨ã€Œé€šç”¨åå¥½ã€å¯èƒ½å°è‡´æ–°ç”¨æˆ¶è¦ºå¾—å…§å®¹éæ–¼æ³›åŒ–ï¼Œæ˜¯å¦éœ€è¦è¨­è¨ˆã€Œå¿«é€Ÿäº’å‹•å•å·ã€æˆ–ã€Œå¼•å°å¼äº’å‹•ã€ï¼Ÿ

### ç¾æœ‰è¨­è¨ˆ
ç›®å‰åƒ…æœ‰é€šç”¨åå¥½ä½œç‚ºåˆå§‹å€¼ï¼Œç¼ºä¹å¿«é€Ÿæ”¶é›†åå¥½çš„æ©Ÿåˆ¶ã€‚

### å»ºè­°è§£æ±ºæ–¹æ¡ˆ

#### 3.1 å¿«é€Ÿäº’å‹•å•å·ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰

**è¨­è¨ˆåŸå‰‡**: 3-5å€‹å•é¡Œï¼Œ30ç§’å…§å®Œæˆ

**å•å·å…§å®¹**:
```json
{
  "questions": [
    {
      "id": "q1",
      "type": "single_choice",
      "question": "ä½ æœ€æ„Ÿèˆˆè¶£çš„å…§å®¹é¡å‹æ˜¯ï¼Ÿ",
      "options": ["æ™‚å°šè¶¨å‹¢", "ç¾é£Ÿæ¨è–¦", "ç¤¾æœƒè¶¨å‹¢"],
      "weight": 0.4
    },
    {
      "id": "q2",
      "type": "multiple_choice",
      "question": "ä½ åå¥½çš„æ–‡å­—é¢¨æ ¼æ˜¯ï¼Ÿï¼ˆå¯å¤šé¸ï¼‰",
      "options": ["ç¶²ç´…èªæ°£", "æ­£å¼å°ˆæ¥­", "å­¸è¡“åš´è¬¹"],
      "weight": 0.3
    },
    {
      "id": "q3",
      "type": "single_choice",
      "question": "ä½ åå¥½çš„ç…§ç‰‡é¢¨æ ¼æ˜¯ï¼Ÿ",
      "options": ["è¿‘æ‹ç´°ç¯€", "å…¨æ™¯å±•ç¤º", "æ··åˆé¢¨æ ¼"],
      "weight": 0.3
    }
  ]
}
```

**å¯¦ç¾é‚è¼¯**:
```python
async def create_initial_preferences_from_questionnaire(user_id, answers):
    """
    å¾å•å·ç­”æ¡ˆå»ºç«‹åˆå§‹åå¥½
    """
    preferences = {
        "user_id": user_id,
        "category_scores": {
            "fashion": 0.33,
            "food": 0.33,
            "social": 0.34
        },
        "style_preferences": {
            "article_style": "influencer",
            "photo_style": "mixed",
            "script_style": "fast_paced"
        }
    }
    
    # æ ¹æ“šå•å·ç­”æ¡ˆèª¿æ•´
    if answers["q1"] == "æ™‚å°šè¶¨å‹¢":
        preferences["category_scores"]["fashion"] = 0.6
        preferences["category_scores"]["food"] = 0.2
        preferences["category_scores"]["social"] = 0.2
    
    if "ç¶²ç´…èªæ°£" in answers["q2"]:
        preferences["style_preferences"]["article_style"] = "influencer"
    
    if answers["q3"] == "è¿‘æ‹ç´°ç¯€":
        preferences["style_preferences"]["photo_style"] = "close_up"
    
    return preferences
```

#### 3.2 å¼•å°å¼äº’å‹•ï¼ˆå‰3æ¬¡ä½¿ç”¨ï¼‰

**è¨­è¨ˆåŸå‰‡**: åœ¨ç”Ÿæˆå…§å®¹å¾Œï¼Œä¸»å‹•å¼•å°ç”¨æˆ¶äº’å‹•

**å¼•å°æµç¨‹**:
```python
class GuidedInteraction:
    async def guide_first_interaction(self, user_id, topic_id):
        """
        å¼•å°é¦–æ¬¡äº’å‹•
        """
        # ç”Ÿæˆå…§å®¹å¾Œï¼Œä¸»å‹•è©¢å•
        guide_message = {
            "type": "interaction_guide",
            "message": "é€™æ˜¯ç‚ºä½ ç”Ÿæˆçš„ç¬¬ä¸€ç¯‡å…§å®¹ï¼Œè«‹å‘Šè¨´æˆ‘å€‘ä½ çš„æƒ³æ³•ï¼š",
            "actions": [
                {"type": "like", "label": "ğŸ‘ å–œæ­¡"},
                {"type": "dislike", "label": "ğŸ‘ ä¸å–œæ­¡"},
                {"type": "edit", "label": "âœï¸ éœ€è¦ä¿®æ”¹"}
            ],
            "priority": "high"
        }
        
        # è¨˜éŒ„å¼•å°äº’å‹•
        await self.record_guided_interaction(user_id, topic_id, guide_message)
    
    async def guide_style_preference(self, user_id, content):
        """
        å¼•å°é¢¨æ ¼åå¥½
        """
        # å¦‚æœç”¨æˆ¶ä¿®æ”¹äº†å…§å®¹ï¼Œåˆ†æä¿®æ”¹æ¨¡å¼
        if content.edit_count > 0:
            style_analysis = await analyze_edit_pattern(content)
            
            # ä¸»å‹•è©¢å•
            if style_analysis.suggested_style != content.original_style:
                guide_message = {
                    "type": "style_confirmation",
                    "message": f"æˆ‘å€‘æ³¨æ„åˆ°ä½ åå¥½ {style_analysis.suggested_style} é¢¨æ ¼ï¼Œæ˜¯å¦è¦å°‡æ­¤è¨­ç‚ºé è¨­ï¼Ÿ",
                    "actions": [
                        {"type": "confirm", "label": "âœ… ç¢ºèª"},
                        {"type": "cancel", "label": "âŒ å–æ¶ˆ"}
                    ]
                }
                return guide_message
```

#### 3.3 å¿«é€Ÿå­¸ç¿’æ©Ÿåˆ¶ï¼ˆå‰10æ¬¡äº’å‹•ï¼‰

**è¨­è¨ˆåŸå‰‡**: å‰10æ¬¡äº’å‹•æ¬Šé‡æ›´é«˜ï¼Œå¿«é€Ÿå»ºç«‹åå¥½æ¨¡å‹

**å¯¦ç¾é‚è¼¯**:
```python
def calculate_preference_with_cold_start(user_id, interactions):
    """
    å†·å•Ÿå‹•æœŸé–“çš„åå¥½è¨ˆç®—ï¼ˆå‰10æ¬¡äº’å‹•æ¬Šé‡æ›´é«˜ï¼‰
    """
    preferences = initialize_default_preferences()
    
    # åˆ†éšæ®µè¨ˆç®—
    early_interactions = [i for i in interactions if i.sequence <= 10]
    later_interactions = [i for i in interactions if i.sequence > 10]
    
    # æ—©æœŸäº’å‹•æ¬Šé‡ = 2.0
    # å¾ŒæœŸäº’å‹•æ¬Šé‡ = 1.0
    early_weight = 2.0
    later_weight = 1.0
    
    for interaction in early_interactions:
        update_preferences(preferences, interaction, weight=early_weight)
    
    for interaction in later_interactions:
        update_preferences(preferences, interaction, weight=later_weight)
    
    return preferences
```

#### 3.4 å†·å•Ÿå‹•å•å· API

**æ–°å¢ç«¯é»**: `POST /api/v1/user/{user_id}/cold-start-questionnaire`

**åŠŸèƒ½**: å–å¾—æˆ–æäº¤å†·å•Ÿå‹•å•å·

**Response (å–å¾—å•å·)**:
```json
{
  "user_id": "user_123",
  "questionnaire": {
    "questions": [...],
    "estimated_time": 30
  }
}
```

**Request (æäº¤ç­”æ¡ˆ)**:
```json
{
  "answers": {
    "q1": "æ™‚å°šè¶¨å‹¢",
    "q2": ["ç¶²ç´…èªæ°£"],
    "q3": "è¿‘æ‹ç´°ç¯€"
  }
}
```

---

## å•é¡Œ 4: å…§å®¹å“è³ªæ§åˆ¶èˆ‡å¯©æ ¸è²¬ä»»

### å•é¡Œæ ¸å¿ƒ
è‡ªå‹•å“è³ªæª¢æ¸¬è‹¥å‡ºç¾èª¤åˆ¤ï¼Œèª°è² è²¬æœ€çµ‚å¯©æ ¸ï¼Ÿæ˜¯å¦éœ€è¦è¨­è¨ˆã€Œäººå·¥å¯©æ ¸éšŠåˆ—ã€æˆ–ã€ŒåŠè‡ªå‹•å¯©æ ¸ã€æ©Ÿåˆ¶ï¼Ÿ

### ç¾æœ‰è¨­è¨ˆ
ç›®å‰åƒ…æœ‰åŸºæœ¬çš„å“è³ªæª¢æ¸¬å»ºè­°ï¼Œç¼ºä¹å®Œæ•´çš„å¯©æ ¸æ©Ÿåˆ¶ã€‚

### å»ºè­°è§£æ±ºæ–¹æ¡ˆ

#### 4.1 å¤šå±¤å“è³ªæª¢æ¸¬æ©Ÿåˆ¶

**æª¢æ¸¬å±¤ç´š**:
```
Level 1: è‡ªå‹•æª¢æ¸¬ï¼ˆèªæ³•ã€é‚è¼¯ã€åŸºæœ¬äº‹å¯¦ï¼‰
  â†“ (é€šé)
Level 2: ä¾†æºé©—è­‰ï¼ˆæª¢æŸ¥å¼•ç”¨ä¾†æºï¼‰
  â†“ (é€šé)
Level 3: ä¸€è‡´æ€§æª¢æŸ¥ï¼ˆæ–‡å­—èˆ‡ç…§ç‰‡åŒ¹é…ï¼‰
  â†“ (é€šé)
Level 4: äººå·¥å¯©æ ¸ï¼ˆå¯é¸ï¼Œé«˜é¢¨éšªå…§å®¹ï¼‰
  â†“ (é€šé)
ç™¼å¸ƒ
```

**å¯¦ç¾é‚è¼¯**:
```python
class ContentQualityControl:
    async def check_content_quality(self, content):
        """
        å¤šå±¤å“è³ªæª¢æ¸¬
        """
        results = {
            "level1_auto_check": await self.auto_check(content),
            "level2_source_verification": await self.verify_sources(content),
            "level3_consistency_check": await self.check_consistency(content),
            "level4_human_review": None
        }
        
        # è¨ˆç®—é¢¨éšªåˆ†æ•¸
        risk_score = calculate_risk_score(results)
        
        # æ±ºå®šæ˜¯å¦éœ€è¦äººå·¥å¯©æ ¸
        if risk_score > 0.7:
            results["level4_human_review"] = await self.add_to_review_queue(content)
            results["status"] = "pending_review"
        elif risk_score > 0.4:
            results["status"] = "flagged"  # æ¨™è¨˜ä½†å¯ç™¼å¸ƒ
        else:
            results["status"] = "approved"
        
        return results
```

#### 4.2 äººå·¥å¯©æ ¸éšŠåˆ—è¨­è¨ˆ

**å¯©æ ¸å„ªå…ˆç´š**:
- **P0 (ç·Šæ€¥)**: äº‹å¯¦éŒ¯èª¤ã€ç‰ˆæ¬Šå•é¡Œ
- **P1 (é«˜)**: ä¾†æºä¸å¯é ã€é‚è¼¯çŸ›ç›¾
- **P2 (ä¸­)**: èªæ³•éŒ¯èª¤ã€é¢¨æ ¼ä¸ä¸€è‡´
- **P3 (ä½)**: è¼•å¾®å•é¡Œã€å„ªåŒ–å»ºè­°

**å¯¦ç¾é‚è¼¯**:
```python
class HumanReviewQueue:
    async def add_to_queue(self, content, reason, priority="P2"):
        """
        åŠ å…¥äººå·¥å¯©æ ¸éšŠåˆ—
        """
        review_item = {
            "content_id": content.id,
            "topic_id": content.topic_id,
            "reason": reason,
            "priority": priority,
            "status": "pending",
            "assigned_to": None,
            "created_at": datetime.utcnow(),
            "auto_check_results": content.quality_check_results
        }
        
        await self.review_queue.insert_one(review_item)
    
    async def assign_reviewer(self, review_id, reviewer_id):
        """
        åˆ†é…å¯©æ ¸å“¡
        """
        await self.review_queue.update_one(
            {"id": review_id},
            {"$set": {
                "assigned_to": reviewer_id,
                "assigned_at": datetime.utcnow(),
                "status": "in_review"
            }}
        )
    
    async def submit_review(self, review_id, decision, comments):
        """
        æäº¤å¯©æ ¸çµæœ
        """
        await self.review_queue.update_one(
            {"id": review_id},
            {"$set": {
                "status": "reviewed",
                "decision": decision,  # "approved" | "rejected" | "needs_revision"
                "comments": comments,
                "reviewed_at": datetime.utcnow()
            }}
        )
```

#### 4.3 åŠè‡ªå‹•å¯©æ ¸æ©Ÿåˆ¶

**è¨­è¨ˆåŸå‰‡**: è‡ªå‹•æª¢æ¸¬ + äººå·¥ç¢ºèªé—œéµæ±ºç­–

**è§¸ç™¼æ¢ä»¶**:
1. é¢¨éšªåˆ†æ•¸ > 0.7ï¼ˆè‡ªå‹•åŠ å…¥å¯©æ ¸éšŠåˆ—ï¼‰
2. ä¾†æºå¯é æ€§ < 0.6ï¼ˆéœ€è¦äººå·¥ç¢ºèªï¼‰
3. ç…§ç‰‡åŒ¹é…åº¦ < 0.7ï¼ˆéœ€è¦äººå·¥ç¢ºèªï¼‰
4. é¡§å®¢æŠ•è¨´ï¼ˆè‡ªå‹•åŠ å…¥å¯©æ ¸éšŠåˆ—ï¼‰

**å¯¦ç¾é‚è¼¯**:
```python
class SemiAutoReview:
    async def process_content(self, content):
        """
        åŠè‡ªå‹•å¯©æ ¸æµç¨‹
        """
        # è‡ªå‹•æª¢æ¸¬
        auto_results = await self.auto_check(content)
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
        if auto_results.risk_score > 0.7:
            # éœ€è¦äººå·¥å¯©æ ¸
            review_item = await self.add_to_review_queue(content, auto_results)
            
            # é€šçŸ¥å¯©æ ¸å“¡
            await self.notify_reviewers(review_item)
            
            return {
                "status": "pending_review",
                "review_id": review_item.id,
                "estimated_time": "2å°æ™‚å…§"
            }
        elif auto_results.risk_score > 0.4:
            # æ¨™è¨˜ä½†å¯ç™¼å¸ƒï¼ˆéœ€è¦å¾ŒçºŒç›£æ§ï¼‰
            await self.flag_content(content, auto_results)
            return {
                "status": "flagged_but_approved",
                "warnings": auto_results.warnings
            }
        else:
            # è‡ªå‹•é€šé
            return {
                "status": "auto_approved",
                "confidence": auto_results.confidence
            }
```

#### 4.4 å¯©æ ¸è²¬ä»»éˆ

**è²¬ä»»åˆ†é…**:
```
ç³»çµ±è‡ªå‹•æª¢æ¸¬ â†’ åˆæ­¥ç¯©é¸
    â†“ (é«˜é¢¨éšª)
äººå·¥å¯©æ ¸å“¡ â†’ å°ˆæ¥­åˆ¤æ–·
    â†“ (é‡å¤§å•é¡Œ)
å…§å®¹ç¸½ç›£ â†’ æœ€çµ‚æ±ºç­–
```

**å¯©æ ¸ API**:
- `GET /api/v1/review/queue` - å–å¾—å¯©æ ¸éšŠåˆ—
- `POST /api/v1/review/{review_id}/assign` - åˆ†é…å¯©æ ¸å“¡
- `POST /api/v1/review/{review_id}/submit` - æäº¤å¯©æ ¸çµæœ

---

## å•é¡Œ 5: ç³»çµ±å¯è§€æ¸¬æ€§èˆ‡å›æº¯èƒ½åŠ›

### å•é¡Œæ ¸å¿ƒ
è‹¥æŸæ¬¡ç”Ÿæˆå…§å®¹è¢«é¡§å®¢è³ªç–‘çœŸå¯¦æ€§ï¼Œç³»çµ±æ˜¯å¦èƒ½å¿«é€Ÿå›æº¯åˆ°ã€Œä¾†æºæˆªåœ– + é©—è­‰ç´€éŒ„ã€ï¼Ÿ

### ç¾æœ‰è¨­è¨ˆ
ç›®å‰æœ‰åŸºæœ¬çš„ä¾†æºå­˜æª”ï¼Œä½†ç¼ºä¹å®Œæ•´çš„è­‰æ“šéˆã€‚

### å»ºè­°è§£æ±ºæ–¹æ¡ˆ

#### 5.1 ä¾†æºè­‰æ“šéˆè¨­è¨ˆ

**è­‰æ“šéˆçµæ§‹**:
```
Topic (ä¸»é¡Œ)
  â”œâ”€â”€ Source Evidence (ä¾†æºè­‰æ“š)
  â”‚   â”œâ”€â”€ Source URL
  â”‚   â”œâ”€â”€ Source Screenshot (æˆªåœ–)
  â”‚   â”œâ”€â”€ Fetched Timestamp
  â”‚   â””â”€â”€ Verification Record (é©—è­‰ç´€éŒ„)
  â”œâ”€â”€ Content Evidence (å…§å®¹è­‰æ“š)
  â”‚   â”œâ”€â”€ Generated Content
  â”‚   â”œâ”€â”€ AI Model Used
  â”‚   â”œâ”€â”€ Prompt Version
  â”‚   â””â”€â”€ Generation Timestamp
  â””â”€â”€ Photo Evidence (ç…§ç‰‡è­‰æ“š)
      â”œâ”€â”€ Photo URL
      â”œâ”€â”€ Photo Source
      â”œâ”€â”€ License Info
      â””â”€â”€ Match Verification
```

**å¯¦ç¾é‚è¼¯**:
```python
class EvidenceChain:
    async def create_evidence_chain(self, topic_id):
        """
        å»ºç«‹å®Œæ•´çš„è­‰æ“šéˆ
        """
        topic = await self.get_topic(topic_id)
        
        evidence_chain = {
            "topic_id": topic_id,
            "created_at": datetime.utcnow(),
            "source_evidence": [],
            "content_evidence": {},
            "photo_evidence": []
        }
        
        # æ”¶é›†ä¾†æºè­‰æ“š
        for source in topic.sources:
            source_evidence = {
                "source_name": source.name,
                "source_url": source.url,
                "screenshot_url": await self.save_screenshot(source.url),
                "fetched_at": source.fetched_at,
                "verification_record": {
                    "verified": source.verified,
                    "reliability": source.reliability,
                    "verified_at": source.verified_at
                }
            }
            evidence_chain["source_evidence"].append(source_evidence)
        
        # æ”¶é›†å…§å®¹è­‰æ“š
        content = await self.get_content(topic_id)
        evidence_chain["content_evidence"] = {
            "article": content.article,
            "script": content.script,
            "ai_model": content.model_used,
            "prompt_version": content.prompt_version,
            "generated_at": content.generated_at,
            "references": content.references
        }
        
        # æ”¶é›†ç…§ç‰‡è­‰æ“š
        photos = await self.get_photos(topic_id)
        for photo in photos:
            photo_evidence = {
                "photo_id": photo.id,
                "photo_url": photo.url,
                "source": photo.source,
                "license": photo.license,
                "match_verification": {
                    "matched_item": photo.matches_item,
                    "match_score": photo.match_score,
                    "verified_at": photo.fetched_at
                }
            }
            evidence_chain["photo_evidence"].append(photo_evidence)
        
        # ä¿å­˜è­‰æ“šéˆ
        await self.save_evidence_chain(evidence_chain)
        
        return evidence_chain
```

#### 5.2 å¿«é€Ÿå›æº¯æ©Ÿåˆ¶

**å›æº¯ API**:
- `GET /api/v1/evidence/{topic_id}` - å–å¾—å®Œæ•´è­‰æ“šéˆ
- `GET /api/v1/evidence/{topic_id}/sources` - å–å¾—ä¾†æºè­‰æ“š
- `GET /api/v1/evidence/{topic_id}/screenshot/{source_id}` - å–å¾—ä¾†æºæˆªåœ–

**å¯¦ç¾é‚è¼¯**:
```python
@router.get("/evidence/{topic_id}")
async def get_evidence_chain(topic_id: str):
    """
    å–å¾—å®Œæ•´è­‰æ“šéˆï¼ˆç”¨æ–¼å›æº¯ï¼‰
    """
    evidence_chain = await evidence_service.get_evidence_chain(topic_id)
    
    if not evidence_chain:
        raise HTTPException(
            status_code=404,
            detail="è­‰æ“šéˆä¸å­˜åœ¨"
        )
    
    return {
        "topic_id": topic_id,
        "evidence_chain": evidence_chain,
        "traceability": {
            "can_trace_to_source": True,
            "can_trace_to_verification": True,
            "can_trace_to_generation": True
        }
    }
```

#### 5.3 å¯©è¨ˆæ—¥èªŒè¨­è¨ˆ

**æ—¥èªŒå…§å®¹**:
- æ‰€æœ‰ä¾†æºè¨ªå•è¨˜éŒ„
- æ‰€æœ‰å…§å®¹ç”Ÿæˆè¨˜éŒ„
- æ‰€æœ‰é©—è­‰æ“ä½œè¨˜éŒ„
- æ‰€æœ‰ä¿®æ”¹è¨˜éŒ„

**å¯¦ç¾é‚è¼¯**:
```python
class AuditLog:
    async def log_source_access(self, source_url, result):
        """
        è¨˜éŒ„ä¾†æºè¨ªå•
        """
        log_entry = {
            "type": "source_access",
            "source_url": source_url,
            "result": result,
            "timestamp": datetime.utcnow(),
            "ip_address": request.client.host
        }
        await self.audit_log.insert_one(log_entry)
    
    async def log_content_generation(self, topic_id, content, model_used):
        """
        è¨˜éŒ„å…§å®¹ç”Ÿæˆ
        """
        log_entry = {
            "type": "content_generation",
            "topic_id": topic_id,
            "model_used": model_used,
            "content_hash": hash(content),
            "timestamp": datetime.utcnow()
        }
        await self.audit_log.insert_one(log_entry)
```

#### 5.4 å¯è§€æ¸¬æ€§å„€è¡¨æ¿

**ç›£æ§æŒ‡æ¨™**:
- ä¾†æºå¥åº·åº¦
- å…§å®¹ç”ŸæˆæˆåŠŸç‡
- ç…§ç‰‡åŒ¹é…æº–ç¢ºåº¦
- å¯©æ ¸éšŠåˆ—é•·åº¦
- è­‰æ“šéˆå®Œæ•´æ€§

**å¯¦ç¾é‚è¼¯**:
```python
@router.get("/observability/dashboard")
async def get_observability_dashboard():
    """
    å–å¾—å¯è§€æ¸¬æ€§å„€è¡¨æ¿æ•¸æ“š
    """
    return {
        "source_health": await get_source_health_metrics(),
        "content_generation": await get_content_generation_metrics(),
        "photo_matching": await get_photo_matching_metrics(),
        "review_queue": await get_review_queue_metrics(),
        "evidence_chain": await get_evidence_chain_metrics()
    }
```

---

## ç¸½çµ

### äº”å€‹å•é¡Œçš„è§£æ±ºæ–¹æ¡ˆ

1. **è³‡æ–™ä¾†æºå†—é¤˜èˆ‡ä¸€è‡´æ€§**
   - âœ… 3-2-1 å‚™æ´æ©Ÿåˆ¶
   - âœ… è·¨ä¾†æºä¸€è‡´æ€§æª¢æŸ¥
   - âœ… ä¾†æºå¥åº·åº¦ç›£æ§

2. **ç…§ç‰‡åŒ¹é…é©—è­‰æµç¨‹**
   - âœ… NLP + CV äº¤å‰æª¢æŸ¥
   - âœ… è¦–è¦ºç‰¹å¾µæå–èˆ‡æ¯”å°
   - âœ… äººå·¥ Fallback æ©Ÿåˆ¶

3. **åå¥½æ¨¡å‹å†·å•Ÿå‹•**
   - âœ… å¿«é€Ÿäº’å‹•å•å·ï¼ˆ3-5é¡Œï¼Œ30ç§’ï¼‰
   - âœ… å¼•å°å¼äº’å‹•ï¼ˆå‰3æ¬¡ä½¿ç”¨ï¼‰
   - âœ… å¿«é€Ÿå­¸ç¿’æ©Ÿåˆ¶ï¼ˆå‰10æ¬¡æ¬Šé‡æ›´é«˜ï¼‰

4. **å…§å®¹å“è³ªæ§åˆ¶**
   - âœ… å¤šå±¤å“è³ªæª¢æ¸¬ï¼ˆ4å±¤ï¼‰
   - âœ… äººå·¥å¯©æ ¸éšŠåˆ—ï¼ˆå„ªå…ˆç´šæ©Ÿåˆ¶ï¼‰
   - âœ… åŠè‡ªå‹•å¯©æ ¸ï¼ˆé¢¨éšªåˆ†æ•¸åˆ¤æ–·ï¼‰

5. **ç³»çµ±å¯è§€æ¸¬æ€§**
   - âœ… å®Œæ•´è­‰æ“šéˆè¨­è¨ˆ
   - âœ… å¿«é€Ÿå›æº¯æ©Ÿåˆ¶
   - âœ… å¯©è¨ˆæ—¥èªŒç³»çµ±
   - âœ… å¯è§€æ¸¬æ€§å„€è¡¨æ¿

### å¯¦æ–½å„ªå…ˆç´š

**Phase 1 (ç«‹å³å¯¦æ–½)**:
- è³‡æ–™ä¾†æºå‚™æ´æ©Ÿåˆ¶
- ç…§ç‰‡åŒ¹é…é©—è­‰ï¼ˆåŸºç¤ç‰ˆï¼‰
- è­‰æ“šéˆè¨­è¨ˆ

**Phase 2 (çŸ­æœŸå¯¦æ–½)**:
- NLP + CV äº¤å‰æª¢æŸ¥
- å†·å•Ÿå‹•å•å·
- äººå·¥å¯©æ ¸éšŠåˆ—

**Phase 3 (ä¸­æœŸå¯¦æ–½)**:
- å¼•å°å¼äº’å‹•
- åŠè‡ªå‹•å¯©æ ¸
- å¯è§€æ¸¬æ€§å„€è¡¨æ¿

---

**å›è¦†ç‰ˆæœ¬**: v1.0  
**å›è¦†æ—¥æœŸ**: 2025-12-30  
**å›è¦†äºº**: AI Agents å¾Œå°ç³»çµ±è¨­è¨ˆåœ˜éšŠ

