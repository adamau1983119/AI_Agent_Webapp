"""
æ¸¬è©¦ç”Ÿæˆã€Œ2026å¹´ Dior æ˜¥å¤showã€å¯¦éš› Sample
"""
import asyncio
import json
from datetime import datetime
from app.database import connect_to_mongo
from app.services.repositories.topic_repository import TopicRepository
from app.services.repositories.content_repository import ContentRepository
from app.services.repositories.image_repository import ImageRepository
from app.services.ai.qwen import QwenService
from app.services.ai.ollama import OllamaService
from app.services.images.image_service_manager import ImageServiceManager
from app.config import settings
from app.models.topic import Category, Status
from app.models.image import ImageSource
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def create_dior_topic():
    """å»ºç«‹ Dior ä¸»é¡Œ"""
    topic_repo = TopicRepository()
    
    topic_data = {
        "id": "dior_2026_spring_summer",
        "title": "2026å¹´ Dior æ˜¥å¤show",
        "category": Category.FASHION,
        "status": Status.PENDING,
        "source": "Dior Official",
        "sources": [
            {
                "name": "Dior Official",
                "url": "https://www.dior.com",
                "type": "official",
                "keywords": ["Dior", "2026", "æ˜¥å¤", "æ™‚è£ç§€", "fashion show", "spring summer", "å·´é»", "èŠ±åœ’", "æµªæ¼«ä¸»ç¾©"],
                "verified": True,
                "verified_at": datetime.utcnow().isoformat(),
                "reliability": "very_high"
            },
            {
                "name": "Vogue Fashion Shows",
                "url": "https://www.vogue.com/fashion-shows/spring-2026-ready-to-wear/dior",
                "type": "fashion_media",
                "keywords": ["Dior", "2026", "spring", "fashion show", "Vogue"],
                "verified": True,
                "verified_at": datetime.utcnow().isoformat(),
                "reliability": "high"
            }
        ],
        "generated_at": datetime.utcnow(),
        "created_at": datetime.utcnow(),
        "updated_at": datetime.utcnow()
    }
    
    try:
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = await topic_repo.get_topic_by_id("dior_2026_spring_summer")
        if existing:
            logger.info("âœ… ä¸»é¡Œå·²å­˜åœ¨ï¼Œä½¿ç”¨ç¾æœ‰ä¸»é¡Œ")
            return existing
        
        # å»ºç«‹æ–°ä¸»é¡Œ
        topic = await topic_repo.create_topic(topic_data)
        logger.info(f"âœ… ä¸»é¡Œå»ºç«‹æˆåŠŸ: {topic['id']}")
        return topic
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹ä¸»é¡Œå¤±æ•—: {e}")
        raise


async def generate_content_for_dior():
    """ç‚º Dior ä¸»é¡Œç”Ÿæˆå…§å®¹"""
    content_repo = ContentRepository()
    topic_repo = TopicRepository()
    
    # æ ¹æ“šé…ç½®é¸æ“‡ AI æœå‹™
    if settings.AI_SERVICE in ["ollama", "ollama_cloud"]:
        ai_service = OllamaService()
        logger.info(f"ä½¿ç”¨ Ollama æœå‹™ï¼ˆ{'é›²ç«¯' if settings.OLLAMA_API_KEY else 'æœ¬åœ°'}ï¼‰")
    elif settings.AI_SERVICE == "qwen":
        ai_service = QwenService()
        logger.info("ä½¿ç”¨é€šç¾©åƒå•æœå‹™")
    else:
        # é è¨­ä½¿ç”¨ Ollamaï¼ˆå¦‚æœæœ‰ API Keyï¼‰æˆ– Qwen
        if settings.OLLAMA_API_KEY:
            ai_service = OllamaService()
            logger.info("ä½¿ç”¨ Ollama é›²ç«¯æœå‹™ï¼ˆè‡ªå‹•é¸æ“‡ï¼‰")
        else:
            ai_service = QwenService()
            logger.info("ä½¿ç”¨é€šç¾©åƒå•æœå‹™ï¼ˆè‡ªå‹•é¸æ“‡ï¼‰")
    
    topic_id = "dior_2026_spring_summer"
    
    # å–å¾—ä¸»é¡Œ
    topic = await topic_repo.get_topic_by_id(topic_id)
    if not topic:
        raise ValueError(f"ä¸»é¡Œä¸å­˜åœ¨: {topic_id}")
    
    # æå–é—œéµå­—
    keywords = []
    for source in topic.get("sources", []):
        if "keywords" in source:
            keywords.extend(source["keywords"])
    
    logger.info(f"ğŸ“ é–‹å§‹ç”Ÿæˆå…§å®¹...")
    logger.info(f"   ä¸»é¡Œ: {topic['title']}")
    logger.info(f"   åˆ†é¡: {topic['category']}")
    logger.info(f"   é—œéµå­—: {', '.join(keywords)}")
    
    # ç”ŸæˆçŸ­æ–‡å’Œè…³æœ¬
    try:
        result = await ai_service.generate_both(
            topic_title=topic["title"],
            topic_category=topic["category"],
            keywords=keywords,
            article_length=500,
            script_duration=30
        )
        
        article = result["article"]
        script = result["script"]
        
        logger.info(f"âœ… å…§å®¹ç”ŸæˆæˆåŠŸ")
        logger.info(f"   çŸ­æ–‡é•·åº¦: {len(article)} å­—")
        logger.info(f"   è…³æœ¬é•·åº¦: {len(script)} å­—")
        
        # è¨ˆç®—å­—æ•¸å’Œæ™‚é•·
        word_count = len(article) + len(script)
        estimated_duration = word_count // 17
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨å…§å®¹
        existing_content = await content_repo.get_content_by_topic_id(topic_id)
        
        now = datetime.utcnow()
        
        if existing_content:
            # æ›´æ–°ç¾æœ‰å…§å®¹
            content_id = existing_content["id"]
            update_data = {
                "article": article,
                "script": script,
                "word_count": word_count,
                "estimated_duration": estimated_duration,
                "model_used": getattr(ai_service, 'model', 'qwen-turbo'),
                "prompt_version": "v1.0",
                "updated_at": now
            }
            
            updated = await content_repo.update_content(
                content_id,
                update_data,
                create_version=True
            )
            
            return updated
        else:
            # å»ºç«‹æ–°å…§å®¹
            content_data = {
                "id": f"content_{topic_id}",
                "topic_id": topic_id,
                "article": article,
                "script": script,
                "word_count": word_count,
                "estimated_duration": estimated_duration,
                "model_used": getattr(ai_service, 'model', 'qwen-turbo'),
                "prompt_version": "v1.0",
                "version": 1,
                "generated_at": now,
                "updated_at": now
            }
            
            created = await content_repo.create_content(content_data)
            return created
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå…§å®¹å¤±æ•—: {e}")
        raise


async def search_images_for_dior():
    """ç‚º Dior ä¸»é¡Œæœå°‹åœ–ç‰‡"""
    image_repo = ImageRepository()
    image_service = ImageServiceManager()
    
    topic_id = "dior_2026_spring_summer"
    
    # æœå°‹é—œéµå­—åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
    search_keywords = [
        "Dior fashion show 2026",
        "fashion runway spring summer",
        "luxury fashion elegant",
        "fashion show paris",
        "haute couture",
        "fashion model runway"
    ]
    
    logger.info(f"ğŸ–¼ï¸  é–‹å§‹æœå°‹åœ–ç‰‡...")
    
    all_images = []
    
    for keywords in search_keywords:
        try:
            logger.info(f"   æœå°‹é—œéµå­—: {keywords}")
            images = await image_service.search_images(
                keywords=keywords,
                page=1,
                limit=10
            )
            
            logger.info(f"   âœ… æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
            all_images.extend(images)
            
            # å¦‚æœå·²ç¶“æ‰¾åˆ°è¶³å¤ çš„åœ–ç‰‡ï¼Œåœæ­¢æœå°‹
            if len(all_images) >= 20:
                break
                
        except Exception as e:
            logger.warning(f"   âš ï¸ æœå°‹å¤±æ•—: {e}ï¼Œç¹¼çºŒä¸‹ä¸€å€‹é—œéµå­—...")
            continue
    
    # å»é‡ï¼ˆæ ¹æ“š URLï¼‰
    seen_urls = set()
    unique_images = []
    for img in all_images:
        url = img.get("url") or img.get("image_url")
        if url and url not in seen_urls:
            seen_urls.add(url)
            unique_images.append(img)
    
    logger.info(f"âœ… ç¸½å…±æ‰¾åˆ° {len(unique_images)} å¼µä¸é‡è¤‡åœ–ç‰‡")
    
    # é¸æ“‡å‰ 8 å¼µåœ–ç‰‡ï¼ˆå¯ä»¥æ ¹æ“šè©•åˆ†é¸æ“‡ï¼Œé€™è£¡ç°¡åŒ–ç‚ºå‰ 8 å¼µï¼‰
    selected_images = unique_images[:8]
    
    # é©—è­‰åœ–ç‰‡ URL æ ¼å¼
    def validate_image_url(url: str) -> bool:
        """é©—è­‰åœ–ç‰‡ URL æ ¼å¼"""
        if not url:
            return False
        # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ HTTP/HTTPS URL
        return url.startswith("http://") or url.startswith("https://")
    
    # å„²å­˜åœ–ç‰‡åˆ°è³‡æ–™åº«
    saved_images = []
    for idx, img_data in enumerate(selected_images, start=1):
        try:
            image_url = img_data.get("url") or img_data.get("image_url")
            
            # é©—è­‰ URL æ ¼å¼
            if not validate_image_url(image_url):
                logger.warning(f"   âš ï¸ åœ–ç‰‡ {idx} URL æ ¼å¼ç„¡æ•ˆï¼Œè·³é: {image_url}")
                continue
            
            image_data = {
                "id": f"img_{topic_id}_{idx}",
                "topic_id": topic_id,
                "url": image_url,  # çœŸå¯¦çš„ API å›æ‡‰ URL
                "thumbnail_url": img_data.get("thumbnail_url") or image_url,
                "source": img_data.get("source", ImageSource.UNSPLASH),
                "photographer": img_data.get("photographer") or img_data.get("author", "Unknown"),
                "photographer_url": img_data.get("photographer_url") or "",
                "description": img_data.get("description") or img_data.get("alt", ""),
                "width": img_data.get("width", 0),
                "height": img_data.get("height", 0),
                "license": img_data.get("license", "Unsplash License"),
                "order": idx,
                "created_at": datetime.utcnow(),
                "api_response": True,  # æ¨™è¨˜ç‚º API å›æ‡‰
                "fetched_at": datetime.utcnow()
            }
            
            created = await image_repo.create_image(image_data)
            saved_images.append(created)
            logger.info(f"   âœ… åœ–ç‰‡ {idx} å·²å„²å­˜")
            logger.info(f"      URL: {image_url[:80]}...")
            logger.info(f"      ä¾†æº: {image_data.get('source')}")
            logger.info(f"      æ”å½±å¸«: {image_data.get('photographer')}")
            
        except Exception as e:
            logger.warning(f"   âš ï¸ å„²å­˜åœ–ç‰‡ {idx} å¤±æ•—: {e}")
            continue
    
    return saved_images


async def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=" * 60)
    logger.info("é–‹å§‹ç”Ÿæˆã€Œ2026å¹´ Dior æ˜¥å¤showã€å¯¦éš› Sample")
    logger.info("=" * 60)
    
    # é å…ˆæª¢æŸ¥é…ç½®
    from app.config import settings
    
    # æª¢æŸ¥ AI æœå‹™é…ç½®
    ai_service_configured = False
    if settings.AI_SERVICE in ["ollama", "ollama_cloud"]:
        if settings.OLLAMA_API_KEY:
            ai_service_configured = True
            logger.info(f"âœ… ä½¿ç”¨ Ollama é›²ç«¯ APIï¼ˆå·²è¨­å®š API Keyï¼‰")
        else:
            logger.warning("âš ï¸ OLLAMA_API_KEY æœªè¨­å®šï¼Œå°‡å˜—è©¦ä½¿ç”¨æœ¬åœ° Ollama")
            ai_service_configured = True  # æœ¬åœ° Ollama ä¸éœ€è¦ API Key
    elif settings.AI_SERVICE == "qwen":
        if settings.QWEN_API_KEY:
            ai_service_configured = True
            logger.info("âœ… ä½¿ç”¨é€šç¾©åƒå• APIï¼ˆå·²è¨­å®š API Keyï¼‰")
        else:
            logger.error("âŒ éŒ¯èª¤ï¼šQWEN_API_KEY æœªè¨­å®š")
            logger.error("   è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š QWEN_API_KEY")
            logger.error("   æˆ–åˆ‡æ›åˆ° Ollama æœå‹™ï¼ˆè¨­å®š AI_SERVICE=ollamaï¼‰")
            logger.error("   åƒè€ƒæ–‡ä»¶ï¼šDior_Sampleå¤±æ•—åŸå› åˆ†æèˆ‡è§£æ±ºæ–¹æ¡ˆ.md")
            return
    else:
        # è‡ªå‹•é¸æ“‡ï¼šå„ªå…ˆä½¿ç”¨ Ollamaï¼ˆå¦‚æœæœ‰ API Keyï¼‰ï¼Œå¦å‰‡ä½¿ç”¨ Qwen
        if settings.OLLAMA_API_KEY:
            ai_service_configured = True
            logger.info("âœ… è‡ªå‹•é¸æ“‡ï¼šä½¿ç”¨ Ollama é›²ç«¯ API")
        elif settings.QWEN_API_KEY:
            ai_service_configured = True
            logger.info("âœ… è‡ªå‹•é¸æ“‡ï¼šä½¿ç”¨é€šç¾©åƒå• API")
        else:
            logger.error("âŒ éŒ¯èª¤ï¼šæœªè¨­å®šä»»ä½• AI æœå‹™çš„ API Key")
            logger.error("   è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®šä»¥ä¸‹ä»»ä¸€é …ï¼š")
            logger.error("   - OLLAMA_API_KEYï¼ˆæ¨è–¦ï¼‰")
            logger.error("   - QWEN_API_KEY")
            logger.error("   åƒè€ƒæ–‡ä»¶ï¼šDior_Sampleå¤±æ•—åŸå› åˆ†æèˆ‡è§£æ±ºæ–¹æ¡ˆ.md")
            return
    
    try:
        # é€£æ¥è³‡æ–™åº«
        await connect_to_mongo()
        logger.info("âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        
        # 1. å»ºç«‹ä¸»é¡Œ
        logger.info("\n" + "=" * 60)
        logger.info("æ­¥é©Ÿ 1: å»ºç«‹ä¸»é¡Œ")
        logger.info("=" * 60)
        topic = await create_dior_topic()
        
        # 2. ç”Ÿæˆå…§å®¹
        logger.info("\n" + "=" * 60)
        logger.info("æ­¥é©Ÿ 2: ç”Ÿæˆå…§å®¹")
        logger.info("=" * 60)
        content = await generate_content_for_dior()
        
        # 3. æœå°‹åœ–ç‰‡
        logger.info("\n" + "=" * 60)
        logger.info("æ­¥é©Ÿ 3: æœå°‹åœ–ç‰‡")
        logger.info("=" * 60)
        images = await search_images_for_dior()
        
        # 4. è¼¸å‡ºçµæœ
        logger.info("\n" + "=" * 60)
        logger.info("ç”Ÿæˆçµæœæ‘˜è¦")
        logger.info("=" * 60)
        logger.info(f"âœ… ä¸»é¡Œ ID: {topic['id']}")
        logger.info(f"âœ… ä¸»é¡Œæ¨™é¡Œ: {topic['title']}")
        logger.info(f"âœ… å…§å®¹ ID: {content['id']}")
        logger.info(f"âœ… çŸ­æ–‡é•·åº¦: {content['word_count']} å­—")
        logger.info(f"âœ… åœ–ç‰‡æ•¸é‡: {len(images)} å¼µ")
        
        # å„²å­˜çµæœåˆ°æª”æ¡ˆ
        result = {
            "topic": {
                "id": topic["id"],
                "title": topic["title"],
                "category": topic["category"],
                "status": topic["status"],
                "sources": topic.get("sources", [])
            },
            "content": {
                "id": content["id"],
                "article": content.get("article", ""),
                "script": content.get("script", ""),
                "word_count": content.get("word_count", 0),
                "estimated_duration": content.get("estimated_duration", 0),
                "model_used": content.get("model_used", "unknown")
            },
            "images": [
                {
                    "id": img["id"],
                    "url": img.get("url", ""),
                    "description": img.get("description", ""),
                    "source": img.get("source", ""),
                    "photographer": img.get("photographer", "")
                }
                for img in images
            ],
            "generated_at": datetime.utcnow().isoformat()
        }
        
        with open("dior_sample_result.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nâœ… çµæœå·²å„²å­˜åˆ°: dior_sample_result.json")
        logger.info("\n" + "=" * 60)
        logger.info("ç”Ÿæˆå®Œæˆï¼")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    finally:
        from app.database import close_mongo_connection
        await close_mongo_connection()


if __name__ == "__main__":
    asyncio.run(main())

