"""
æ”¹é€²ç‰ˆï¼šæ¸¬è©¦ç”Ÿæˆã€Œ2026å¹´ Dior æ˜¥å¤showã€å¯¦éš› Sample
åŒ…å«æ›´å¥½çš„éŒ¯èª¤è™•ç†å’Œé…ç½®æª¢æŸ¥
"""
import asyncio
import json
import sys
from datetime import datetime
from pathlib import Path

# è¨­å®šè¼¸å‡ºç·¨ç¢¼
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

from app.database import connect_to_mongo
from app.services.repositories.topic_repository import TopicRepository
from app.services.repositories.content_repository import ContentRepository
from app.services.repositories.image_repository import ImageRepository
from app.services.ai.qwen import QwenService
from app.services.images.image_service_manager import ImageServiceManager
from app.models.topic import Category, Status
from app.models.image import ImageSource
from app.config import settings
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def check_prerequisites():
    """æª¢æŸ¥å‰ç½®æ¢ä»¶"""
    logger.info("æª¢æŸ¥å‰ç½®æ¢ä»¶...")
    
    issues = []
    
    # æª¢æŸ¥ API Key
    if not settings.QWEN_API_KEY:
        issues.append("QWEN_API_KEY æœªè¨­å®š")
    
    # æª¢æŸ¥ MongoDB URL
    if not settings.MONGODB_URL:
        issues.append("MONGODB_URL æœªè¨­å®š")
    
    if issues:
        logger.error("âŒ ç™¼ç¾é…ç½®å•é¡Œï¼š")
        for issue in issues:
            logger.error(f"   - {issue}")
        logger.error("\nè«‹åŸ·è¡Œè¨ºæ–·è…³æœ¬æª¢æŸ¥é…ç½®ï¼š")
        logger.error("   python diagnose_dior_test.py")
        logger.error("\næˆ–åƒè€ƒæ–‡ä»¶ï¼šDior_Sampleå¤±æ•—åŸå› åˆ†æèˆ‡è§£æ±ºæ–¹æ¡ˆ.md")
        return False
    
    logger.info("âœ… å‰ç½®æ¢ä»¶æª¢æŸ¥é€šé")
    return True


async def create_dior_topic():
    """å»ºç«‹ Dior ä¸»é¡Œ"""
    topic_repo = TopicRepository()
    
    topic_data = {
        "id": "dior_2026_spring_summer",
        "title": "2026å¹´ Dior æ˜¥å¤show",
        "category": Category.FASHION,
        "status": Status.PENDING,
        "source": "Dior Official",
        "sources": [
            {
                "name": "Dior Official",
                "url": "https://www.dior.com",
                "type": "official",
                "keywords": ["Dior", "2026", "æ˜¥å¤", "æ™‚è£ç§€", "fashion show", "spring summer", "å·´é»", "èŠ±åœ’", "æµªæ¼«ä¸»ç¾©"],
                "verified": True,
                "verified_at": datetime.utcnow().isoformat(),
                "reliability": "very_high"
            },
            {
                "name": "Vogue Fashion Shows",
                "url": "https://www.vogue.com/fashion-shows/spring-2026-ready-to-wear/dior",
                "type": "fashion_media",
                "keywords": ["Dior", "2026", "spring", "fashion show", "Vogue"],
                "verified": True,
                "verified_at": datetime.utcnow().isoformat(),
                "reliability": "high"
            }
        ],
        "generated_at": datetime.utcnow(),
        "created_at": datetime.utcnow(),
        "updated_at": datetime.utcnow()
    }
    
    try:
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = await topic_repo.get_topic_by_id("dior_2026_spring_summer")
        if existing:
            logger.info("âœ… ä¸»é¡Œå·²å­˜åœ¨ï¼Œä½¿ç”¨ç¾æœ‰ä¸»é¡Œ")
            return existing
        
        # å»ºç«‹æ–°ä¸»é¡Œ
        topic = await topic_repo.create_topic(topic_data)
        logger.info(f"âœ… ä¸»é¡Œå»ºç«‹æˆåŠŸ: {topic['id']}")
        return topic
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹ä¸»é¡Œå¤±æ•—: {e}")
        raise


async def generate_content_for_dior():
    """ç‚º Dior ä¸»é¡Œç”Ÿæˆå…§å®¹"""
    content_repo = ContentRepository()
    topic_repo = TopicRepository()
    
    # æª¢æŸ¥ API Key
    if not settings.QWEN_API_KEY:
        raise ValueError("QWEN_API_KEY æœªè¨­å®šï¼Œç„¡æ³•ç”Ÿæˆå…§å®¹")
    
    ai_service = QwenService()
    topic_id = "dior_2026_spring_summer"
    
    # å–å¾—ä¸»é¡Œ
    topic = await topic_repo.get_topic_by_id(topic_id)
    if not topic:
        raise ValueError(f"ä¸»é¡Œä¸å­˜åœ¨: {topic_id}")
    
    # æå–é—œéµå­—
    keywords = []
    for source in topic.get("sources", []):
        if "keywords" in source:
            keywords.extend(source["keywords"])
    
    logger.info(f"ğŸ“ é–‹å§‹ç”Ÿæˆå…§å®¹...")
    logger.info(f"   ä¸»é¡Œ: {topic['title']}")
    logger.info(f"   åˆ†é¡: {topic['category']}")
    logger.info(f"   é—œéµå­—: {', '.join(keywords[:5])}...")
    
    # ç”ŸæˆçŸ­æ–‡å’Œè…³æœ¬
    try:
        logger.info("   èª¿ç”¨ AI æœå‹™ç”Ÿæˆå…§å®¹ï¼ˆé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ï¼‰...")
        result = await ai_service.generate_both(
            topic_title=topic["title"],
            topic_category=topic["category"],
            keywords=keywords,
            article_length=500,
            script_duration=30
        )
        
        article = result["article"]
        script = result["script"]
        
        logger.info(f"âœ… å…§å®¹ç”ŸæˆæˆåŠŸ")
        logger.info(f"   çŸ­æ–‡é•·åº¦: {len(article)} å­—")
        logger.info(f"   è…³æœ¬é•·åº¦: {len(script)} å­—")
        
        # è¨ˆç®—å­—æ•¸å’Œæ™‚é•·
        word_count = len(article) + len(script)
        estimated_duration = word_count // 17
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨å…§å®¹
        existing_content = await content_repo.get_content_by_topic_id(topic_id)
        
        now = datetime.utcnow()
        
        if existing_content:
            # æ›´æ–°ç¾æœ‰å…§å®¹
            content_id = existing_content["id"]
            update_data = {
                "article": article,
                "script": script,
                "word_count": word_count,
                "estimated_duration": estimated_duration,
                "model_used": getattr(ai_service, 'model', 'qwen-turbo'),
                "prompt_version": "v1.0",
                "updated_at": now
            }
            
            updated = await content_repo.update_content(
                content_id,
                update_data,
                create_version=True
            )
            
            return updated
        else:
            # å»ºç«‹æ–°å…§å®¹
            content_data = {
                "id": f"content_{topic_id}",
                "topic_id": topic_id,
                "article": article,
                "script": script,
                "word_count": word_count,
                "estimated_duration": estimated_duration,
                "model_used": getattr(ai_service, 'model', 'qwen-turbo'),
                "prompt_version": "v1.0",
                "version": 1,
                "generated_at": now,
                "updated_at": now
            }
            
            created = await content_repo.create_content(content_data)
            return created
            
    except ValueError as e:
        if "API Key" in str(e):
            logger.error(f"âŒ é…ç½®éŒ¯èª¤: {e}")
            logger.error("   è«‹æª¢æŸ¥ .env æª”æ¡ˆä¸­çš„ QWEN_API_KEY è¨­å®š")
            raise
        else:
            logger.error(f"âŒ ç”Ÿæˆå…§å®¹å¤±æ•—: {e}")
            raise
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå…§å®¹å¤±æ•—: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise


async def search_images_for_dior():
    """ç‚º Dior ä¸»é¡Œæœå°‹åœ–ç‰‡"""
    image_repo = ImageRepository()
    image_service = ImageServiceManager()
    
    topic_id = "dior_2026_spring_summer"
    
    # æœå°‹é—œéµå­—åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
    search_keywords = [
        "Dior fashion show 2026",
        "fashion runway spring summer",
        "luxury fashion elegant",
        "fashion show paris",
        "haute couture",
        "fashion model runway"
    ]
    
    logger.info(f"ğŸ–¼ï¸  é–‹å§‹æœå°‹åœ–ç‰‡...")
    
    all_images = []
    
    for keywords in search_keywords:
        try:
            logger.info(f"   æœå°‹é—œéµå­—: {keywords}")
            images = await image_service.search_images(
                keywords=keywords,
                page=1,
                limit=10
            )
            
            logger.info(f"   âœ… æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
            all_images.extend(images)
            
            # å¦‚æœå·²ç¶“æ‰¾åˆ°è¶³å¤ çš„åœ–ç‰‡ï¼Œåœæ­¢æœå°‹
            if len(all_images) >= 20:
                break
                
        except ValueError as e:
            # API Key æœªè¨­å®šï¼Œè·³é
            logger.warning(f"   âš ï¸ {e}ï¼Œè·³éæ­¤æœå‹™...")
            continue
        except Exception as e:
            logger.warning(f"   âš ï¸ æœå°‹å¤±æ•—: {e}ï¼Œç¹¼çºŒä¸‹ä¸€å€‹é—œéµå­—...")
            continue
    
    # å»é‡ï¼ˆæ ¹æ“š URLï¼‰
    seen_urls = set()
    unique_images = []
    for img in all_images:
        url = img.get("url") or img.get("image_url")
        if url and url not in seen_urls:
            seen_urls.add(url)
            unique_images.append(img)
    
    logger.info(f"âœ… ç¸½å…±æ‰¾åˆ° {len(unique_images)} å¼µä¸é‡è¤‡åœ–ç‰‡")
    
    # é¸æ“‡å‰ 8 å¼µåœ–ç‰‡
    selected_images = unique_images[:8]
    
    # é©—è­‰åœ–ç‰‡ URL æ ¼å¼
    def validate_image_url(url: str) -> bool:
        """é©—è­‰åœ–ç‰‡ URL æ ¼å¼"""
        if not url:
            return False
        return url.startswith("http://") or url.startswith("https://")
    
    # å„²å­˜åœ–ç‰‡åˆ°è³‡æ–™åº«
    saved_images = []
    for idx, img_data in enumerate(selected_images, start=1):
        try:
            image_url = img_data.get("url") or img_data.get("image_url")
            
            # é©—è­‰ URL æ ¼å¼
            if not validate_image_url(image_url):
                logger.warning(f"   âš ï¸ åœ–ç‰‡ {idx} URL æ ¼å¼ç„¡æ•ˆï¼Œè·³é: {image_url}")
                continue
            
            image_data = {
                "id": f"img_{topic_id}_{idx}",
                "topic_id": topic_id,
                "url": image_url,
                "thumbnail_url": img_data.get("thumbnail_url") or image_url,
                "source": img_data.get("source", ImageSource.UNSPLASH),
                "photographer": img_data.get("photographer") or img_data.get("author", "Unknown"),
                "photographer_url": img_data.get("photographer_url") or "",
                "description": img_data.get("description") or img_data.get("alt", ""),
                "width": img_data.get("width", 0),
                "height": img_data.get("height", 0),
                "license": img_data.get("license", "Unsplash License"),
                "order": idx,
                "created_at": datetime.utcnow(),
                "api_response": True,
                "fetched_at": datetime.utcnow()
            }
            
            created = await image_repo.create_image(image_data)
            saved_images.append(created)
            logger.info(f"   âœ… åœ–ç‰‡ {idx} å·²å„²å­˜")
            logger.info(f"      URL: {image_url[:80]}...")
            logger.info(f"      ä¾†æº: {image_data.get('source')}")
            
        except Exception as e:
            logger.warning(f"   âš ï¸ å„²å­˜åœ–ç‰‡ {idx} å¤±æ•—: {e}")
            continue
    
    return saved_images


async def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=" * 60)
    logger.info("é–‹å§‹ç”Ÿæˆã€Œ2026å¹´ Dior æ˜¥å¤showã€å¯¦éš› Sample")
    logger.info("=" * 60)
    
    # æª¢æŸ¥å‰ç½®æ¢ä»¶
    if not check_prerequisites():
        logger.error("\nâŒ å‰ç½®æ¢ä»¶æª¢æŸ¥å¤±æ•—ï¼Œè«‹å…ˆè§£æ±ºé…ç½®å•é¡Œ")
        return
    
    try:
        # é€£æ¥è³‡æ–™åº«
        logger.info("\né€£æ¥è³‡æ–™åº«...")
        await connect_to_mongo()
        logger.info("âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        
        # 1. å»ºç«‹ä¸»é¡Œ
        logger.info("\n" + "=" * 60)
        logger.info("æ­¥é©Ÿ 1: å»ºç«‹ä¸»é¡Œ")
        logger.info("=" * 60)
        topic = await create_dior_topic()
        
        # 2. ç”Ÿæˆå…§å®¹
        logger.info("\n" + "=" * 60)
        logger.info("æ­¥é©Ÿ 2: ç”Ÿæˆå…§å®¹")
        logger.info("=" * 60)
        content = await generate_content_for_dior()
        
        # 3. æœå°‹åœ–ç‰‡
        logger.info("\n" + "=" * 60)
        logger.info("æ­¥é©Ÿ 3: æœå°‹åœ–ç‰‡")
        logger.info("=" * 60)
        images = await search_images_for_dior()
        
        # 4. è¼¸å‡ºçµæœ
        logger.info("\n" + "=" * 60)
        logger.info("ç”Ÿæˆçµæœæ‘˜è¦")
        logger.info("=" * 60)
        logger.info(f"âœ… ä¸»é¡Œ ID: {topic['id']}")
        logger.info(f"âœ… ä¸»é¡Œæ¨™é¡Œ: {topic['title']}")
        logger.info(f"âœ… å…§å®¹ ID: {content['id']}")
        logger.info(f"âœ… çŸ­æ–‡é•·åº¦: {content.get('word_count', 0)} å­—")
        logger.info(f"âœ… åœ–ç‰‡æ•¸é‡: {len(images)} å¼µ")
        
        # å„²å­˜çµæœåˆ°æª”æ¡ˆ
        result = {
            "topic": {
                "id": topic["id"],
                "title": topic["title"],
                "category": topic["category"],
                "status": topic["status"],
                "sources": topic.get("sources", [])
            },
            "content": {
                "id": content["id"],
                "article": content.get("article", ""),
                "script": content.get("script", ""),
                "word_count": content.get("word_count", 0),
                "estimated_duration": content.get("estimated_duration", 0),
                "model_used": content.get("model_used", "unknown")
            },
            "images": [
                {
                    "id": img["id"],
                    "url": img.get("url", ""),
                    "description": img.get("description", ""),
                    "source": img.get("source", ""),
                    "photographer": img.get("photographer", "")
                }
                for img in images
            ],
            "generated_at": datetime.utcnow().isoformat()
        }
        
        result_file = Path("dior_sample_result.json")
        with open(result_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nâœ… çµæœå·²å„²å­˜åˆ°: {result_file.absolute()}")
        logger.info("\n" + "=" * 60)
        logger.info("ç”Ÿæˆå®Œæˆï¼")
        logger.info("=" * 60)
        
    except ValueError as e:
        logger.error(f"\nâŒ é…ç½®éŒ¯èª¤: {e}")
        logger.error("   è«‹æª¢æŸ¥é…ç½®æª”æ¡ˆä¸¦é‡æ–°åŸ·è¡Œ")
    except Exception as e:
        logger.error(f"\nâŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        from app.database import close_mongo_connection
        await close_mongo_connection()


if __name__ == "__main__":
    asyncio.run(main())

