"""
å»ºç«‹ã€Œç¾é£Ÿæ¨ä»‹ã€ä¸»é¡Œç¯„ä¾‹
ç¤ºç¯„å¦‚ä½•å»ºç«‹ FOOD é¡åˆ¥çš„ä¸»é¡Œä¸¦ç”Ÿæˆå…§å®¹å’Œåœ–ç‰‡
"""
import asyncio
import json
from datetime import datetime
from app.database import connect_to_mongo, close_mongo_connection
from app.services.repositories.topic_repository import TopicRepository
from app.services.repositories.content_repository import ContentRepository
from app.services.repositories.image_repository import ImageRepository
from app.services.ai.qwen import QwenService
from app.services.ai.ollama import OllamaService
from app.services.images.image_service_manager import ImageServiceManager
from app.config import settings
from app.models.topic import Category, Status
from app.models.image import ImageSource
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def create_food_topic():
    """å»ºç«‹ç¾é£Ÿæ¨ä»‹ä¸»é¡Œç¯„ä¾‹ï¼š2026å¹´å°åŒ—ç±³å…¶æ—é¤å»³æ¨è–¦"""
    topic_repo = TopicRepository()
    
    topic_data = {
        "id": "taipei_michelin_2026",
        "title": "2026å¹´å°åŒ—ç±³å…¶æ—é¤å»³æ¨è–¦",
        "category": Category.FOOD,  # ç¾é£Ÿåˆ†é¡
        "status": Status.PENDING,
        "source": "ç±³å…¶æ—æŒ‡å—",
        "sources": [
            {
                "name": "ç±³å…¶æ—æŒ‡å—å®˜æ–¹ç¶²ç«™",
                "url": "https://guide.michelin.com/tw/zh_TW/taipei",
                "type": "official",
                "keywords": ["ç±³å…¶æ—", "å°åŒ—", "é¤å»³", "ç¾é£Ÿ", "fine dining", "Michelin", "Taipei", "restaurant"],
                "verified": True,
                "verified_at": datetime.utcnow().isoformat(),
                "reliability": "very_high"
            },
            {
                "name": "OpenRice å°ç£",
                "url": "https://www.openrice.com/zh/tw",
                "type": "food_platform",
                "keywords": ["OpenRice", "å°åŒ—", "é¤å»³æ¨è–¦", "ç¾é£Ÿ", "restaurant review"],
                "verified": True,
                "verified_at": datetime.utcnow().isoformat(),
                "reliability": "high"
            }
        ],
        "generated_at": datetime.utcnow(),
        "created_at": datetime.utcnow(),
        "updated_at": datetime.utcnow()
    }
    
    try:
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = await topic_repo.get_topic_by_id("taipei_michelin_2026")
        if existing:
            logger.info("âœ… ä¸»é¡Œå·²å­˜åœ¨ï¼Œä½¿ç”¨ç¾æœ‰ä¸»é¡Œ")
            return existing
        
        # å»ºç«‹æ–°ä¸»é¡Œ
        topic = await topic_repo.create_topic(topic_data)
        logger.info(f"âœ… ç¾é£Ÿä¸»é¡Œå»ºç«‹æˆåŠŸ: {topic['id']}")
        return topic
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹ä¸»é¡Œå¤±æ•—: {e}")
        raise


async def generate_content_for_food():
    """ç‚ºç¾é£Ÿä¸»é¡Œç”Ÿæˆå…§å®¹"""
    content_repo = ContentRepository()
    topic_repo = TopicRepository()
    
    # æ ¹æ“šé…ç½®é¸æ“‡ AI æœå‹™
    if settings.AI_SERVICE in ["ollama", "ollama_cloud"]:
        ai_service = OllamaService()
        logger.info(f"ä½¿ç”¨ Ollama æœå‹™ï¼ˆ{'é›²ç«¯' if settings.OLLAMA_API_KEY else 'æœ¬åœ°'}ï¼‰")
    elif settings.AI_SERVICE == "qwen":
        ai_service = QwenService()
        logger.info("ä½¿ç”¨é€šç¾©åƒå•æœå‹™")
    else:
        if settings.OLLAMA_API_KEY:
            ai_service = OllamaService()
            logger.info("ä½¿ç”¨ Ollama é›²ç«¯æœå‹™ï¼ˆè‡ªå‹•é¸æ“‡ï¼‰")
        else:
            ai_service = QwenService()
            logger.info("ä½¿ç”¨é€šç¾©åƒå•æœå‹™ï¼ˆè‡ªå‹•é¸æ“‡ï¼‰")
    
    topic_id = "taipei_michelin_2026"
    
    # å–å¾—ä¸»é¡Œ
    topic = await topic_repo.get_topic_by_id(topic_id)
    if not topic:
        raise ValueError(f"ä¸»é¡Œä¸å­˜åœ¨: {topic_id}")
    
    # æå–é—œéµå­—
    keywords = []
    for source in topic.get("sources", []):
        keywords.extend(source.get("keywords", []))
    keywords = list(set(keywords))  # å»é‡
    
    logger.info(f"ğŸ“ é–‹å§‹ç”Ÿæˆç¾é£Ÿå…§å®¹ï¼Œé—œéµå­—: {keywords}")
    
    try:
        # ç”ŸæˆçŸ­æ–‡ï¼ˆ500å­—ä»¥å…§ï¼‰å’Œè…³æœ¬ï¼ˆ30ç§’ä»¥å…§ï¼‰
        result = await ai_service.generate_both(
            topic_title=topic["title"],
            topic_category=topic["category"],
            keywords=keywords,
            article_length=500,
            script_duration=30
        )
        
        article = result.get("article", "")
        script = result.get("script", "")
        
        logger.info(f"âœ… å…§å®¹ç”ŸæˆæˆåŠŸ")
        logger.info(f"ğŸ“„ çŸ­æ–‡é•·åº¦: {len(article)} å­—")
        logger.info(f"ğŸ¬ è…³æœ¬é•·åº¦: {len(script)} å­—")
        
        # è¨ˆç®—å­—æ•¸
        word_count = len(article) + len(script)
        
        # å„²å­˜å…§å®¹
        content_data = {
            "topic_id": topic_id,
            "article": article,
            "script": script,
            "word_count": word_count,
            "generated_at": datetime.utcnow(),
            "updated_at": datetime.utcnow(),
            "versions": []
        }
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨å…§å®¹
        existing_content = await content_repo.get_content_by_topic_id(topic_id)
        if existing_content:
            # æ›´æ–°ç¾æœ‰å…§å®¹
            await content_repo.update_content(
                existing_content["id"],
                content_data,
                create_version=True
            )
            logger.info("âœ… å…§å®¹å·²æ›´æ–°")
        else:
            # å»ºç«‹æ–°å…§å®¹
            await content_repo.create_content(content_data)
            logger.info("âœ… å…§å®¹å·²å»ºç«‹")
        
        return {"article": article, "script": script}
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå…§å®¹å¤±æ•—: {e}")
        raise


async def search_images_for_food():
    """ç‚ºç¾é£Ÿä¸»é¡Œæœå°‹åœ–ç‰‡"""
    image_repo = ImageRepository()
    image_manager = ImageServiceManager()
    
    topic_id = "taipei_michelin_2026"
    
    # ç¾é£Ÿç›¸é—œé—œéµå­—
    keywords = "å°åŒ— ç±³å…¶æ— é¤å»³ ç¾é£Ÿ fine dining Taipei Michelin restaurant"
    
    logger.info(f"ğŸ–¼ï¸ é–‹å§‹æœå°‹ç¾é£Ÿåœ–ç‰‡ï¼Œé—œéµå­—: {keywords}")
    
    try:
        # æœå°‹åœ–ç‰‡
        images = await image_manager.search_images(
            keywords=keywords,
            page=1,
            limit=8  # é¸æ“‡ 8 å¼µåœ–ç‰‡
        )
        
        if not images:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°åœ–ç‰‡")
            return []
        
        logger.info(f"âœ… æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
        
        # åˆªé™¤ç¾æœ‰åœ–ç‰‡
        existing_images = await image_repo.get_images_by_topic_id(topic_id)
        for img in existing_images:
            await image_repo.delete_image(img["id"])
        
        # å„²å­˜æ–°åœ–ç‰‡
        saved_images = []
        for idx, img in enumerate(images[:8]):  # æœ€å¤šå„²å­˜ 8 å¼µ
            image_data = {
                "topic_id": topic_id,
                "url": img.get("url", ""),
                "source": ImageSource(img.get("source", "Unsplash")),
                "photographer": img.get("photographer"),
                "photographer_url": img.get("photographer_url"),
                "license": img.get("license", "Unsplash License"),
                "keywords": img.get("keywords", []),
                "order": idx,
                "width": img.get("width"),
                "height": img.get("height"),
                "fetched_at": datetime.utcnow(),
                "api_response": True,  # æ¨™è¨˜ç‚º API å›æ‡‰
                "fetched_at": datetime.utcnow()
            }
            
            image = await image_repo.create_image(image_data)
            saved_images.append(image)
            logger.info(f"âœ… åœ–ç‰‡ {idx + 1}/8 å·²å„²å­˜: {img.get('url', '')[:50]}...")
        
        logger.info(f"âœ… å…±å„²å­˜ {len(saved_images)} å¼µåœ–ç‰‡")
        return saved_images
    except Exception as e:
        logger.error(f"âŒ æœå°‹åœ–ç‰‡å¤±æ•—: {e}")
        raise


async def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=" * 60)
    logger.info("ğŸ½ï¸ é–‹å§‹å»ºç«‹ç¾é£Ÿæ¨ä»‹ä¸»é¡Œç¯„ä¾‹")
    logger.info("=" * 60)
    
    try:
        # é€£æ¥è³‡æ–™åº«
        await connect_to_mongo()
        logger.info("âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        
        # 1. å»ºç«‹ä¸»é¡Œ
        logger.info("\nğŸ“‹ æ­¥é©Ÿ 1: å»ºç«‹ç¾é£Ÿä¸»é¡Œ")
        topic = await create_food_topic()
        
        # 2. ç”Ÿæˆå…§å®¹
        logger.info("\nğŸ“ æ­¥é©Ÿ 2: ç”Ÿæˆå…§å®¹")
        content = await generate_content_for_food()
        
        # 3. æœå°‹åœ–ç‰‡
        logger.info("\nğŸ–¼ï¸ æ­¥é©Ÿ 3: æœå°‹åœ–ç‰‡")
        images = await search_images_for_food()
        
        # 4. å„²å­˜çµæœ
        result = {
            "topic": {
                "id": topic["id"],
                "title": topic["title"],
                "category": topic["category"],
                "status": topic["status"]
            },
            "content": {
                "article": content["article"],
                "script": content["script"],
                "word_count": len(content["article"]) + len(content["script"])
            },
            "images": [
                {
                    "url": img["url"],
                    "source": img["source"],
                    "order": img["order"]
                }
                for img in images
            ],
            "created_at": datetime.utcnow().isoformat()
        }
        
        # å„²å­˜åˆ°æª”æ¡ˆ
        with open("food_sample_result.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… ç¾é£Ÿæ¨ä»‹ä¸»é¡Œå»ºç«‹å®Œæˆï¼")
        logger.info("=" * 60)
        logger.info(f"ğŸ“„ çµæœå·²å„²å­˜åˆ°: food_sample_result.json")
        logger.info(f"ğŸŒ å¯ä»¥åœ¨ Dashboard æŸ¥çœ‹: http://localhost:3000/topics/{topic['id']}")
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await close_mongo_connection()


if __name__ == "__main__":
    asyncio.run(main())

